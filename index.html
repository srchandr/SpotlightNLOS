<!DOCTYPE html>
<html>


<head>
    <meta charset="utf-8">
    <meta name="description"
        content="Learning-based Spotlight Position Optimization for Non-Line-of-Sight Human Localization and Posture Classification ">
    <meta name="keywords" content="NLOS, Lighting, GNN">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Learning-based Spotlight Position Optimization for Non-Line-of-Sight Human Localization and Posture Classification</title>



    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="icon" href="./static/images/favicon.svg">

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
</head>

<body>


    <section class="hero">
        <div class="hero-body">
            <div class="container is-max-desktop">
                <div class="columns is-centered">
                    <div class="column has-text-centered">
                        <h1 class="title is-1 publication-title">Learning-based Spotlight Position Optimization for Non-Line-of-Sight Human
                            Localization and Posture Classification</h1>
                        <div class="is-size-5 publication-authors">
                            
                            <span class="author-block">
                                Sreenithy Chandran<sup>1</sup>,
                            </span>
                            <span class="author-block">
                                Tatsuya Yatagawa<sup>2</sup>,
                            </span>
                            <span class="author-block">
                                Hiroyuki Kubo<sup>3</sup>,
                            </span>
                            <span class="author-block">
                                Suren Jayasuriya<sup>1</sup>,
                            </span>                         

                        <div class="is-size-5 publication-authors">
                            <span class="author-block"><sup>1</sup>Arizona State University</span>
                            <span class="author-block"><sup>2</sup>Hitotsubashi University</span>
                            <span class="author-block"><sup>3</sup>Chiba University</span>
                        </div>

                        <div class="column has-text-centered">
                            <div class="publication-links">
                                 <!-- PDF Link. -->
                                <span class="link-block">
                                    <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Chandran_Learning-Based_Spotlight_Position_Optimization_for_Non-Line-of-Sight_Human_Localization_and_Posture_WACV_2024_paper.pdf"
                                    class="external-link button is-normal is-rounded is-dark">
                                    <span class="icon">
                                        <i class="fas fa-file-pdf"></i>
                                    </span>
                                    <span>Paper</span>
                                    </a>
                                </span>
                               
                                <!-- Code Link. -->
                                <!--span class="link-block">
                                    <a href="https://github.com/srchandr/Learning-Spotlight-Optimisation-NLOS/tree/main"
                                     class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span-->
                                <!-- Dataset Link. -->
                                <span class="link-block">
                                    <a href="https://www.dropbox.com/scl/fo/74h5pwdxfb78a0izs3e3o/h?rlkey=967z3i05gmrs78401bewfkr9f&dl=0"
                                        class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="far fa-images"></i>
                                        </span>
                                        <span>Code & Data</span>
                                    </a>
                            </div>

                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <section class="hero teaser">
        <div class="container is-max-desktop">
          <div class="hero-body">
            <img src="./static/images/teaser.png"
                 class="teaser-image"
                 alt="Teaser image."/>
                 <h2 class="subtitle has-text-centered">
                    <!-- <span class="dnerf">PAC-Net</span> turns selfie videos from your phone into -->
                    Given the polygonal mesh of a target scene, our method
                predicts which area of the scene to illuminate with a spotlight and
                maximize light scatter information from a hidden person. Then,
                we capture RGB images of the wall visible from the camera under
                optimal illumination. Finally, our neural network predicts the 2D
                position and posture of the hidden person.
                  </h2>
            
          </div>
        </div>
      </section>


   


    <section class="section">
        <div class="container is-max-desktop">
            <!-- Abstract. -->
            <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                    <h2 class="title is-3">Abstract</h2>
                    <div class="content has-text-justified">
                        <p>
                            We present an active data-driven NLOS posture classification and tracking pipeline that works with
                            a standard RGB camera and single spotlight illumination.
                        </p>
                        <p>
                            Non-line-of-sight imaging (NLOS) is the process of estimating information about a scene that
                            is hidden from the direct line of sight of the camera. NLOS imaging typically requires
                            time-resolved detectors and a laser source for illumination, which are both expensive and
                            computationally intensive to handle. In this paper, we propose an NLOS-based localization
                            and posture classification technique that uses an off-the-shelf projector and camera system.
                            We leverage a message-passing neural network to learn a visible scene geometry and predict
                            the best position to be spotlighted by the projector that can maximize the NLOS signal. The
                            neural network is trained end-to-end and the network parameters are optimized to maximize
                            the NLOS performance. Unlike prior deep-learning-based NLOS techniques that assume planar
                            relay walls, our system allows us to handle line-of-sight scenes where scene geometries are
                            more arbitrary. Our method demonstrates state-of-the-art performance in object localization
                            and position classification using both synthetic and real scenes.
                        </p>

                    </div>
                </div>
            </div>
            <!--/ Abstract. -->


        </div>
   



    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Video</h2>
          <div class="publication-video">
            <iframe src="./static/videos/video.mp4"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>



    <!-- Real-Tracking video. -->
    <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Real-Tracking Results</h2>
          <div class="publication-video">
            <iframe src="./static/videos/Tracking.mp4"
                    frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
      <!--/ Paper video. -->
    </div>

    <div class="row">
        <div class="col-md-8 col-md-offset-2">
            <h3>
                Video
            </h3>
            <div class="text-center">
                <div style="position:relative;padding-top:56.25%;">
                    <iframe src="./static/videos/Tracking.mp4" allowfullscreen
                        style="position:absolute;top:0;left:0;width:100%;height:100%;"></iframe>
                </div>
            </div>
        </div>
    </div>

  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{chandran2024learning,
        title={Learning-Based Spotlight Position Optimization for Non-Line-of-Sight Human Localization and Posture Classification},
        author={Chandran, Sreenithy and Yatagawa, Tatsuya and Kubo, Hiroyuki and Jayasuriya, Suren},
        booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
        pages={4218--4227},
        year={2024}
      }</code></pre>
    </div>
  </section>


  <footer class="footer">
    <div class="container">
      <div class="content has-text-centered">
        <a class="icon-link"
           href="./static/videos/nerfies_paper.pdf">
          <i class="fas fa-file-pdf"></i>
        </a>
        <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
          <i class="fab fa-github"></i>
        </a>
      </div>
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This website is licensed under a <a rel="license"
                                                  href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
              Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
            <p>
              Website template borrowed from <a
                href="https://github.com/nerfies/nerfies.github.io">source code</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>
  
  </body>
  </html>