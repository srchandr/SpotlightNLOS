<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description" content="Learning-based Spotlight Position Optimization for Non-Line-of-Sight Human Localization and Posture Classification ">
        <meta name="keywords" content="NLOS, Lighting, GNN">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>Learning-based Spotlight Position Optimization for Non-Line-of-Sight Human Localization and Posture Classification</title>
        <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
        <link rel="stylesheet" href="./static/css/bulma.min.css">
        <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
        <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
        <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
        <link rel="stylesheet" href="./static/css/index.css">
        <link rel="icon" href="./static/images/favicon.svg">
        <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
        <script defer src="./static/js/fontawesome.all.min.js"></script>
        <script src="./static/js/bulma-carousel.min.js"></script>
        <script src="./static/js/bulma-slider.min.js"></script>
        <script src="./static/js/index.js"></script>
    </head>
    <body>
        <section class="hero">
            <div class="hero-body">
                <div class="container is-max-desktop">
                    <div class="columns is-centered">
                        <div class="column has-text-centered">
                            <h1 class="title is-1 publication-title">
                                Learning-based Spotlight Position Optimization for Non-Line-of-Sight Human
                            Localization and Posture Classification
                            </h1>
                            <div class="is-size-5 publication-authors">
                                <span class="author-block">
                                    <a>
                                        Sreenithy Chandran
                                    </a>
                                    <sup>1</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a>Tatsuya Yatagawa</a>
                                    <sup>2</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a>Hiroyuki Kubo</a>
                                    <sup>3</sup>
                                    ,
                                </span>
                                <span class="author-block">
                                    <a>Suren Jayasuriya</a>
                                    <sup>1</sup>
                                </span>
                                <div class="is-size-5 publication-authors">
                                    <span class="author-block">
                                        <sup>1</sup>
                                        Arizona State University,
                                    </span>
                                    <span class="author-block">
                                        <sup>2</sup>
                                        Hitotsubashi University,
                                    </span>
                                    <span class="author-block">
                                        <sup>3</sup>
                                        Chiba University
                                    </span>
                                </div>
                                <div class="column has-text-centered">
                                    <div class="publication-links">
                                        <!-- PDF Link. -->
                                        <span class="link-block">
                                            <a href="https://openaccess.thecvf.com/content/WACV2024/papers/Chandran_Learning-Based_Spotlight_Position_Optimization_for_Non-Line-of-Sight_Human_Localization_and_Posture_WACV_2024_paper.pdf" class="external-link button is-normal is-rounded is-dark">
                                                <span class="icon">
                                                    <i class="fas fa-file-pdf"></i>
                                                </span>
                                                <span>Paper</span>
                                            </a>
                                        </span>
                                        <span class="link-block">
                                            <a href="./static/videos/supplemental.pdf" class="external-link button is-normal is-rounded is-dark">
                                                <span class="icon">
                                                    <i class="fas fa-file-pdf"></i>
                                                </span>
                                                <span>Supplemental Paper</span>
                                            </a>
                                        </span>
                                        <!-- Code Link. -->
                                        <!--span class="link-block">
                                    <a href="https://github.com/srchandr/Learning-Spotlight-Optimisation-NLOS/tree/main"
                                     class="external-link button is-normal is-rounded is-dark">
                                        <span class="icon">
                                            <i class="fab fa-github"></i>
                                        </span>
                                        <span>Code</span>
                                    </a>
                                </span-->
                                        <!-- Dataset Link. -->
                                        <span class="link-block">
                                            <a href="https://www.dropbox.com/scl/fo/74h5pwdxfb78a0izs3e3o/h?rlkey=967z3i05gmrs78401bewfkr9f&dl=0" class="external-link button is-normal is-rounded is-dark">
                                                <span class="icon">
                                                    <i class="far fa-images"></i>
                                                </span>
                                                <span>Code & Data</span>
                                            </a>
                                        </div>
                                    </div>
                                </div>
                            </div>
                        </div>
                    </div>
                </section>
                <section class="hero teaser">
                    <div class="container is-max-desktop">
                        <div class="columns is-vcentered">
                            <div class="column has-text-centered">
                                <img src="./static/images/teaser.png" alt="Teaser Image">
                                <p>
                                    Given the polygonal mesh of a target scene, our method
                    predicts which area of the scene to illuminate with a spotlight and
                    maximize light scatter information from a hidden person. Then,
                    we capture RGB images of the wall visible from the camera under
                    optimal illumination. Finally, our neural network predicts the 2D
                    position and posture of the hidden person.
                                </p>
                            </div>
                        </div>
                    </div>
                </section>
                <section class="section">
                    <div class="container is-max-desktop">
                        <!-- Abstract. -->
                        <div class="columns is-centered has-text-centered">
                            <div class="column is-four-fifths">
                                <h2 class="title is-3">Abstract</h2>
                                <div class="content has-text-justified">
                                    <p>
                                        We present an active data-driven NLOS posture classification and tracking pipeline that works with
                            a standard RGB camera and single spotlight illumination.
                                    </p>
                                    <p>
                                        Non-line-of-sight imaging (NLOS) is the process of estimating information about a scene that
                            is hidden from the direct line of sight of the camera. NLOS imaging typically requires
                            time-resolved detectors and a laser source for illumination, which are both expensive and
                            computationally intensive to handle.
                                    </p>
                                    <p>
                                        In this paper, we propose an NLOS-based localization
                            and posture classification technique that uses an off-the-shelf projector and camera system.
                            We leverage a message-passing neural network to learn a visible scene geometry and predict
                            the best position to be spotlighted by the projector that can maximize the NLOS signal. The
                            neural network is trained end-to-end and the network parameters are optimized to maximize
                            the NLOS performance.
                                    </p>
                                    <p>
                                        Unlike prior deep-learning-based NLOS techniques that assume planar
                            relay walls, our system allows us to handle line-of-sight scenes where scene geometries are
                            more arbitrary. Our method demonstrates state-of-the-art performance in object localization
                            and position classification using both synthetic and real scenes.
                                    </p>
                                </div>
                            </div>
                        </div>
                        <!--/ Abstract. -->
                    </div>
                </section>
                <section class="section">
                    <div class="container is-max-desktop">
                        <!-- Paper video. -->
                        <div class="columns is-centered has-text-centered">
                            <div class="column is-four-fifths">
                                <h2 class="title is-3">Video</h2>
                                <div class="publication-video">
                                    <iframe
                                        src="./static/videos/video.mp4"
                                        frameborder="0"
                                        allow="autoplay; encrypted-media"
                                        allowfullscreen
                                    ></iframe>
                                </div>
                            </div>
                        </div>
                        <!--/ Paper video. -->
                    </div>
                </section>
                <section class="section">
                    <div class="container is-max-desktop">
                        <!-- Pipeline. -->
                        <div class="columns is-centered has-text-centered">
                            <div class="column is-full-width">
                                <h2 class="title is-3">Proposed Pipeline</h2>
                                <div class="content has-text-justified">
                                    <p>
                                        The light position calibration, rendering stage, and recognition blocks are used in training, while the light position calibration, capture stage and recognition blocks are used in real data inference.
                                    </p>
                                </div>
                                <div class="columns is-vcentered">
                                    <div class="column has-text-centered">
                                        <img src="./static/images/pipeline.png" alt="Pipeline of using PAC-Net to perform real-time NLOS Tracking">
                                        <p>Visualization of tracking pipeline with PAC-Net</p>
                                    </div>
                                </div>
                                <h3 class="title is-4">Illumination Estimation Network</h3>
                                <div class="content has-text-justified">
                                    <p>
                                        The primary question that our study aims to
                            address is finding out where to shine the spotlight on a visible surface. To address this, we introduce an illumination
                            estimation network (IEN). The IEN takes a mesh of a scene
                            and outputs the nodes of the triangle that have to be illuminated, to maximize NLOS information
                                    </p>
                                </div>
                                <br>
                                <div class="columns is-vcentered">
                                  <div class="column has-text-centered">
                                      <img src="./static/images/IEN.jpg" alt="Pipeline of using PAC-Net to perform real-time NLOS Tracking">
                                      <p>Visualization of tracking pipeline with PAC-Net</p>
                                  </div>
                              </div>
                            </div>
                        </div>
                    </section>
                    <section class="section">
                        <div class="container is-max-desktop">
                            <!-- Real-Tracking video. -->
                            <div class="columns is-centered has-text-centered">
                                <div class="column is-four-fifths">
                                    <h2 class="title is-3">Real-Tracking Results</h2>
                                    <div class="publication-video">
                                        <iframe
                                            src="./static/videos/Tracking.mp4"
                                            frameborder="0"
                                            allow="autoplay; encrypted-media"
                                            allowfullscreen
                                        ></iframe>
                                    </div>
                                </div>
                            </div>
                            <!--/ Paper video. -->
                        </div>
                    </section>
                    <section class="section" id="BibTeX">
                        <div class="container is-max-desktop content">
                            <h2 class="title">BibTeX</h2>
                            <pre>
                                <code>
                                    @inproceedings{chandran2024learning,
        title={Learning-Based Spotlight Position Optimization for Non-Line-of-Sight Human Localization and Posture Classification},
        author={Chandran, Sreenithy and Yatagawa, Tatsuya and Kubo, Hiroyuki and Jayasuriya, Suren},
        booktitle={Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision},
        pages={4218--4227},
        year={2024}
      }
                                </code>
                            </pre>
                        </div>
                    </section>
                    <footer class="footer">
                        <div class="columns is-centered">
                            <div class="column is-8">
                                <div class="content">
                                    <p>
                                        This website is licensed under a
                                        <a rel="license" href="http://creativecommons.org/licenses/by-sa/4.0/">
                                            Creative
              Commons Attribution-ShareAlike 4.0 International License
                                        </a>
                                        .
                                    </p>
                                    <p>
                                        Website template borrowed from
                                        <a href="https://github.com/nerfies/nerfies.github.io">source code</a>
                                        .
                                    </p>
                                </div>
                            </div>
                        </div>
                    </div>
                </footer>
            </body>
        </html>
